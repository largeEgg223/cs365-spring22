{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Gaussian MLE\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "I have $n=100$ pieces of indepdendent and identicially distrubuted (i.i.d) data related to some measurement that is drawn from a **normal distribution**.\n",
    "\n",
    "Your task is to write code that computes $\\mu_{MLE}$ and $\\sigma_{MLE}$, which represent the mean and standard deviation computed via MLE, respectively, of the underlying normal distribution for the dataset \"MLE_dataset.npy\"\n",
    "\n",
    "## Variable Definitions\n",
    "\n",
    "1. x = collection of data points ($x_1,x_2,...,x_n$). Loaded in as a numpy array of shape (100,)\n",
    "2. $\\mu$ = mean of the normal distribution\n",
    "3. $\\sigma$ = standard deviation of the normal distribution\n",
    "\n",
    "## Useful Numpy functions\n",
    "\n",
    "1. x.shape : returns a tuple that contains the dimension(s) of the numpy array variable name \"x\"\n",
    "\n",
    "## Starting information\n",
    "\n",
    "You are given \"MLE_dataset.npy\" which contains the aforementioned data in the form of a numpy array.\n",
    "\n",
    "You are also given a \"load\" function which, given the path to \"MLE_dataset.npy\", will load the values into a numpy array variable and return said variable.\n",
    "\n",
    "For a single piece of data, $x_i$, if the data is drawn from a normal distribution, the likelihood of that data given some values $\\mu$ and $\\sigma^2$ can be represented as:\n",
    "\n",
    "$$p(x_i | \\mu, \\sigma^2) = \\mathcal{N}(x_i; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} * \\text{exp} \\ [-\\frac{1}{2}(\\frac{x_i - \\mu}{\\sigma})^2]$$\n",
    "\n",
    "In our case, we aren't dealing with a single observation, but $n=100$ observations. Because our observations are **independent**, we can represent our likelihood function for all observations as the product of the individual observations:\n",
    "\n",
    "$$p(x | \\mu, \\sigma^2) = \\Pi_{i=1}^N \\mathcal{N}(x_i; \\mu, \\sigma^2) = (\\frac{1}{2\\pi\\sigma^2})^{n/2} * \\text{exp} \\ [-\\frac{1}{2}\\sum_{i=1}^N (\\frac{x_i - \\mu}{\\sigma})^2]$$\n",
    "\n",
    "\n",
    "## Task\n",
    "\n",
    "Using the starting information, your task is to:\n",
    "1. Derrive the formula for $\\mu_{MLE}$\n",
    "2. Derrive the formula for $\\sigma_{MLE}$\n",
    "3. Write code based on your answers to (1) and (2) that correctly finds $\\mu_{MLE}$ and $\\sigma_{MLE}$ for the data set \"MLE_dataset.npy\"\n",
    "\n",
    "## MLE estimates for $\\mu$ and $\\sigma^2$ (not given to students)\n",
    "\n",
    "$$\\mu_{MLE} = \\frac{1}{n} \\sum_{i=1}^n x_i$$\n",
    "\n",
    "$$ \\sigma^2_{MLE} = \\frac{1}{n} \\sum_{i=1}^n(x_i-\\mu_{MLE})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not given to students\n",
    "\n",
    "#generation of data points with mu_true = 100, sigma_true = 10\n",
    "'''\n",
    "n = 100 #number of data points\n",
    "mu_true = 100\n",
    "sigma_true = 10\n",
    "dataset = []\n",
    "for i in range(n):\n",
    "    dataset.append(np.random.normal(mu_true,scale=sigma_true))\n",
    "dataset = np.asarray(dataset)\n",
    "\n",
    "#np.save(\"./MLE_dataset.npy\",dataset)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_estimate:  102.65639598061982  || sigma estimate:  9.743253619192297\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load(path):\n",
    "    '''\n",
    "    loads \"MLE_dataset.npy\" given its path into variable 'dataset'\n",
    "    '''\n",
    "    dataset = np.load(path)\n",
    "    return dataset\n",
    "    \n",
    "def MLE(dataset):\n",
    "    mu = 0\n",
    "    sigma = 0\n",
    "    \n",
    "    ''' YOUR CODE HERE '''\n",
    "    for i in range(dataset.shape[0]):\n",
    "        mu += dataset[i]\n",
    "    mu /= dataset.shape[0]\n",
    "    \n",
    "    \n",
    "    for i in range(dataset.shape[0]):\n",
    "        sigma += (dataset[i] - mu)**2\n",
    "    sigma /= dataset.shape[0]\n",
    "    sigma = np.sqrt(sigma)\n",
    "    \n",
    "    ''' END YOUR CODE'''\n",
    "    \n",
    "    return mu, sigma\n",
    "\n",
    "'''YOUR TEST CODE HERE'''\n",
    "dataset = np.load(\"./MLE_dataset.npy\")\n",
    "mu_guess, sigma_guess = MLE(dataset)\n",
    "print(\"mu_estimate: \", mu_guess, \" || sigma estimate: \", sigma_guess )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Gaussian EM\n",
    "\n",
    "## Problem statement\n",
    "\n",
    "Let us add a layer of difficulty to the problem of estimating the underlying distribution(s) of our data. Previously. we knew that all of our data came from a single underlying normal distribution.\n",
    "\n",
    "For this problem, I have gone out and collected a brand new data set consisting of $n=200$ data points. These data points are drawn from **one of two unknown gaussian distributions**.\n",
    "\n",
    "To keep the notation consistent, I will use the subscript ID $k = \\{0,1\\}$ to represent which gaussian a parameter/variable is referring to.\n",
    "\n",
    "For instance, $\\mu_k$ represents the mean of the gaussian with ID $k$. $\\mu_0$ represents the mean of the first gaussian, and $\\mu_1$ represents the mean of the second gaussian\n",
    "\n",
    "## Variable definitions\n",
    "\n",
    "1. $k$: id of the gaussian distributions. {0,1} \n",
    "2. $n$: number of data points. 200 in this case\n",
    "3. $\\mu_k$: the mean of normal distribution $k$\n",
    "4. $\\sigma_k$: the std of normal distribution $k$\n",
    "5. $\\pi_k$: the prior probability of normal distribution $k$\n",
    "7. $t$: current step number\n",
    "8. $z_i = k$: represents the idea that i-th data point was drawn from gaussian $k$\n",
    "9. $x_i$: i-th data point\n",
    "\n",
    "## Task Description:\n",
    "\n",
    "To make things clear, here is a list of things we do and don't know.\n",
    "\n",
    "**Do know:**\n",
    "1. Our data points, $x = x_1, x_2, ..., x_n$ for $n = 1$ to $n=200$\n",
    "2. $\\mu_0^{t=0}, \\sigma_0^{t=0}, \\pi_0^{t=0}$ which represent an initial guess for the  mean, std, and prior  of the first gaussian with ID $k=0$\n",
    "3. $\\mu_1^{t=0}, \\sigma_1^{t=0}, \\pi_1^{t=0}$ which represent an initial guess for the  mean, std, and prior  of the second gaussian with ID $k=1$\n",
    "4. $\\pi_0^{t=0}$ and $\\pi_1^{t=0}$ which represent an initial guess for the prior probabilities of gaussian 0 and gaussian 1, respectively\n",
    "5. The number of iterations your EM algorithm should run for.\n",
    "6. Let us define the variable $\\theta_k^t$ to be the set ($\\hat{\\mu_k^t}, \\hat{\\sigma_k^t}, \\hat{\\pi_k^t})$, which is our current estimate at time step t for the three unknown parameters of gaussian k. \n",
    "\n",
    "**Don't know:**\n",
    "1. The true means, $\\mu_0$ and $\\mu_1$ for both gaussian distributions\n",
    "2. The true standard deviations, $\\sigma_0$ and $\\sigma_1$ for both gaussian distributions \n",
    "3. Which gaussian distribution, $k=0$ or $k=1$, a point, $x_i$, came from.\n",
    "4. The true fraction of our points that came from gaussian $k=0$ and the true fraction of our points that came from gaussian $k=1$\n",
    "\n",
    "\n",
    "Your end goal is to implement an algorithm that implements EM and returns the following:\n",
    "1. $\\hat{\\mu_0}, \\hat{\\sigma_0}, \\hat{\\pi_0}$ which represent the final EM estimate the mean, standard deviation (std), and prior of the first gaussian with ID $k=0$\n",
    "2. $\\hat{\\mu_0}, \\hat{\\sigma_0}, \\hat{\\pi_0}$ which represent the final EM estimate of the mean, standard deviation (std), and prior of the first gaussian with ID $k=1$\n",
    "\n",
    "### Recommended task order:\n",
    "\n",
    "1. Write code that implements E step \n",
    "2. Write code that implements M step \n",
    "\n",
    "\n",
    "## E - Step - should I give them this info?\n",
    "1. $P(z_i = k | x_i, \\theta_k^t)$ reflects the responsibility the k-th class has for the i-th data point\n",
    "$$P(z_i = k | x_i, \\theta_k^t) = \\frac{P(x_i | z_i = k, \\theta_k^t)*\\pi_k}{P(x_i | \\theta_k^t)}$$ \\\n",
    "$$= \\frac{P(x_i | z_i = k, \\theta_k^t)*\\pi_k}{\\sum_{k=0}^{1}P(x_i | z_i = k, \\theta_k^t)*\\pi_k}$$\n",
    "\n",
    "\n",
    "\n",
    "## M - Step - should I give them this info?\n",
    "\n",
    "\n",
    "$$\\mu_k^{t+1} = \\frac{\\sum_{i=1}^n x_i * P(z_i = k | x_i, \\theta_k^t)}{\\sum_i^n P(z_i = k | x_i, \\theta_k^t)}$$\n",
    "\n",
    "\n",
    "$$\\sigma_k^{t+1} = (\\frac{\\sum_{i=1}^n(\\mu_k^{t+1} - x_i)^2 P(z_i = k | x_i, \\theta_k^t)}{\\sum_{i=1}^{n}P(z_i = k | x_i, \\theta_k^t)})^{1/2}$$\n",
    "\n",
    "\n",
    "$$\\pi_k^{t+1} = \\frac{\\sum_{i=1}^n P(z_i = k | x_i, \\theta_k^t)}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not given to students\n",
    "#data generation for EM\n",
    "'''\n",
    "class_probs_true = [0.4, 0.6]\n",
    "mus_true = [100, 200]\n",
    "sigmas_true = [24, 21]\n",
    "random_seed = None # for reproducability\n",
    "n_samples = 200\n",
    "n_iterations = 100\n",
    "n_classes = 2\n",
    "\n",
    "dataset = []\n",
    "for c in range(len(class_probs_true)):\n",
    "    for i in range(int(class_probs_true[c]*n_samples)):\n",
    "        dataset.append(np.random.normal(mus_true[c],scale=sigmas_true[c]))\n",
    "\n",
    "dataset = np.asarray(dataset)\n",
    "\n",
    "np.save(\"EM_dataset.npy\", dataset)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True pis:  [0.4, 0.6]\n",
      "True mus:  [100, 200]\n",
      "True sigmas:  [24, 21]\n",
      "initial mu:  [ 90 210]\n",
      "initial sigmas:   [28 19]\n",
      "initial pi:  [0.3 0.7]\n",
      "\n",
      "-------iter:  0 ------------------------\n",
      "pis:  [0.42194944 0.57805056]\n",
      "mus:  [101.37853784 202.42662628]\n",
      "sigmas:  [23.98148408 19.30987141]\n",
      "\n",
      "-------iter:  1 ------------------------\n",
      "pis:  [0.41486436 0.58513564]\n",
      "mus:  [100.44327673 201.86619613]\n",
      "sigmas:  [23.05069349 19.87583409]\n",
      "\n",
      "-------iter:  2 ------------------------\n",
      "pis:  [0.41088789 0.58911211]\n",
      "mus:  [ 99.9228902  201.54455128]\n",
      "sigmas:  [22.52267853 20.20569715]\n",
      "\n",
      "-------iter:  3 ------------------------\n",
      "pis:  [0.40869937 0.59130063]\n",
      "mus:  [ 99.64273507 201.3620698 ]\n",
      "sigmas:  [22.24247102 20.39816386]\n",
      "\n",
      "-------iter:  4 ------------------------\n",
      "pis:  [0.40751351 0.59248649]\n",
      "mus:  [ 99.49329212 201.26126611]\n",
      "sigmas:  [22.09484496 20.50651385]\n",
      "\n",
      "-------iter:  5 ------------------------\n",
      "pis:  [0.40687721 0.59312279]\n",
      "mus:  [ 99.41386731 201.20657422]\n",
      "sigmas:  [22.01700576 20.56596472]\n",
      "\n",
      "-------iter:  6 ------------------------\n",
      "pis:  [0.40653768 0.59346232]\n",
      "mus:  [ 99.37171894 201.17720954]\n",
      "sigmas:  [21.97589161 20.5980892 ]\n",
      "\n",
      "-------iter:  7 ------------------------\n",
      "pis:  [0.40635706 0.59364294]\n",
      "mus:  [ 99.34936548 201.16153504]\n",
      "sigmas:  [21.95414423 20.61529763]\n",
      "\n",
      "-------iter:  8 ------------------------\n",
      "pis:  [0.40626112 0.59373888]\n",
      "mus:  [ 99.33751308 201.1531948 ]\n",
      "sigmas:  [21.94262997 20.62447168]\n",
      "\n",
      "-------iter:  9 ------------------------\n",
      "pis:  [0.40621022 0.59378978]\n",
      "mus:  [ 99.33122925 201.14876468]\n",
      "sigmas:  [21.93653022 20.62934975]\n",
      "\n",
      "-------iter:  10 ------------------------\n",
      "pis:  [0.40618322 0.59381678]\n",
      "mus:  [ 99.32789786 201.14641367]\n",
      "sigmas:  [21.93329779 20.63193991]\n",
      "\n",
      "-------iter:  11 ------------------------\n",
      "pis:  [0.4061689 0.5938311]\n",
      "mus:  [ 99.32613176 201.14516664]\n",
      "sigmas:  [21.93158454 20.63331421]\n",
      "\n",
      "-------iter:  12 ------------------------\n",
      "pis:  [0.40616131 0.59383869]\n",
      "mus:  [ 99.32519548 201.14450536]\n",
      "sigmas:  [21.93067639 20.63404309]\n",
      "\n",
      "-------iter:  13 ------------------------\n",
      "pis:  [0.40615728 0.59384272]\n",
      "mus:  [ 99.32469913 201.14415473]\n",
      "sigmas:  [21.93019498 20.63442958]\n",
      "\n",
      "-------iter:  14 ------------------------\n",
      "pis:  [0.40615515 0.59384485]\n",
      "mus:  [ 99.324436   201.14396884]\n",
      "sigmas:  [21.92993978 20.6346345 ]\n",
      "True pis:  [0.4, 0.6]\n",
      "True mus:  [100, 200]\n",
      "True sigmas:  [24, 21]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "def load(path):\n",
    "    dataset = np.load(path)\n",
    "    return dataset\n",
    "\n",
    "def em(dataset, k, n_iterations):\n",
    "    '''\n",
    "    Input:\n",
    "        dataset - np array containing the data\n",
    "        k - int representing the number of underlying gaussian distributions\n",
    "        n_iterations - int representing number of iterations EM should run for\n",
    "        \n",
    "    output:\n",
    "        \n",
    "    '''\n",
    "    #n_classes = k\n",
    "    #n_samples = n\n",
    "    n_samples = dataset.shape[0]\n",
    "\n",
    "    # Initial guesses for the parameters\n",
    "    mus = np.asarray([90, 210])\n",
    "    sigmas = np.asarray([28,19])\n",
    "    pi = np.asarray([0.3,.7])\n",
    "    \n",
    "    print(\"initial mu: \", mus)\n",
    "    print(\"initial sigmas:  \", sigmas)\n",
    "    print(\"initial pi: \", pi)\n",
    "            \n",
    "    for em_iter in (range(n_iterations)):\n",
    "            print(\"\")\n",
    "            print('-------iter: ', em_iter, '------------------------')\n",
    "            \n",
    "            \n",
    "            #E Step\n",
    "            #ws = responsibilities of each gaussian for each data point. shape = (k,n_samples)\n",
    "            ws = np.zeros((k, dataset.shape[0]))\n",
    "            for i in range(n_samples):\n",
    "                for c in range(mus.shape[0]):\n",
    "                    class_likelihood = scipy.stats.norm(mus[c], sigmas[c]).pdf(dataset[i])*pi[c]\n",
    "                    ws[c, i] = class_likelihood\n",
    "            #print(k0)\n",
    "            #print(ws[1,:])\n",
    "            #assert 1== 0\n",
    "            #normalize ws for each class\n",
    "            original_ws = np.copy(ws)\n",
    "            ws[0,:] = ws[0,:]/(original_ws[0,:] + original_ws[1,:])\n",
    "            ws[1,:] = ws[1,:]/(original_ws[0,:] + original_ws[1,:])\n",
    "            \n",
    "            #m step\n",
    "            '''\n",
    "            using the normalized ws from above, we can compute our next guess for pis, mus, and sigmas\n",
    "            \n",
    "            '''\n",
    "            pis = np.zeros(k) \n",
    "            for j in range(mus.shape[0]): #for each mean\n",
    "                for i in range(n_samples): #iterate over all samples and sum up their ws\n",
    "                    pis[j] += ws[j,i]\n",
    "            pis /= n_samples\n",
    "            print(\"pis: \", pis)\n",
    "            \n",
    "            mus = np.zeros((k))\n",
    "            for j in range(k):\n",
    "                for i in range(n_samples):\n",
    "                    mus[j] += ws[j, i] * dataset[i]\n",
    "                mus[j] /= ws[j,:].sum()\n",
    "            print(\"mus: \", mus)\n",
    "            \n",
    "            #print('sums: ', ws[0].sum(), ws[1].sum())\n",
    "            #assert 1 == 0\n",
    "            sigmas = np.zeros(k)\n",
    "            for j in range(k):\n",
    "                for i in range(n_samples):\n",
    "                    ys = dataset[i]-mus[j]\n",
    "                    sigmas[j] += ws[j, i] * ys**2\n",
    "                sigmas[j] /= ws[j].sum()\n",
    "            for s in range(sigmas.shape[0]):\n",
    "                sigmas[s] = np.sqrt(sigmas[s])\n",
    "            print(\"sigmas: \", sigmas)\n",
    "\n",
    "    return pi, mus, sigmas\n",
    "\n",
    "def main():\n",
    "    n_samples = 200\n",
    "    n_iterations = 15\n",
    "    k = 2\n",
    "    \n",
    "    #true values will not be given to students\n",
    "    class_probs_true = [0.4, 0.6]\n",
    "    mus_true = [100, 200]\n",
    "    sigmas_true = [24, 21]\n",
    "    random_seed = None # for reproducability\n",
    "\n",
    "    dataset = np.load(\"EM_dataset.npy\")\n",
    "#     dataset = []\n",
    "#     for c in range(len(class_probs_true)):\n",
    "#         for i in range(int(class_probs_true[c]*n_samples)):\n",
    "#             dataset.append(np.random.normal(mus_true[c],scale=sigmas_true[c]))\n",
    "\n",
    "#     #dataset = np.asarray(dataset)\n",
    "\n",
    "    print(\"True pis: \", class_probs_true)\n",
    "    print(\"True mus: \", mus_true)\n",
    "    print(\"True sigmas: \", sigmas_true)\n",
    "\n",
    "    class_probs, mus, sigmas = em(dataset, k, n_iterations)\n",
    "    \n",
    "    print(\"True pis: \", class_probs_true)\n",
    "    print(\"True mus: \", mus_true)\n",
    "    print(\"True sigmas: \", sigmas_true)\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
